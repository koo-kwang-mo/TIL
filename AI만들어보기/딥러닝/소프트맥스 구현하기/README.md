### 1. 활성화 함수, 소프트맥스 함수 구현하기

기본적인 형태는 모든 입력의 exp한 값을 모두 더한 값을 k번쨰 입력의 exp한 값에 나눈 형태가 k번째 출력이 되는 것이다.

<img scr = '그림1.JPG'>

하지만 이대로 코드를 만들게 된다면 수가 너무 크거나 작아서 오버플로우에 빠지게 된다. 이를 해결하기 위해 가장 우항에서 처럼 위 아래에 C를 곱해주어 비교적 작은 수로 연산을 유도한다.


def softmax(a):
    c = np.max(a) # overflow 방지를위한 변수
    exp_a = np.exp(a - c) # overflow 대책 
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a

    return y


이러한 소프트 맥스 함수의 출력은 0~1.0 사이이며 모든 출력의 합은 1이다.
 또한, 전체에 대한 k번째 값의 비율을 의미함으로 '확률'로 해설할 수 있다.
 거기에 소프트 맥스 함수를 적용해도 각 원소의 대소 관계는 변하지 않아 신경망으로 분류할 때 출력층의 소프트 맥스 함수를 생략해도 된다.

